{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "# Replace with your actual token\n",
        "kaggle_api_dict = {\"username\":\"\",\"key\":\"\"}\n",
        "\n",
        "# Write to kaggle.json\n",
        "with open(\"/kaggle/working/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_api_dict, f)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T21:20:57.826351Z",
          "iopub.execute_input": "2025-04-06T21:20:57.826709Z",
          "iopub.status.idle": "2025-04-06T21:20:57.832207Z",
          "shell.execute_reply.started": "2025-04-06T21:20:57.826681Z",
          "shell.execute_reply": "2025-04-06T21:20:57.831429Z"
        },
        "id": "lpBJYb467PQP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "shutil.move(\"/kaggle/working/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T21:21:00.222238Z",
          "iopub.execute_input": "2025-04-06T21:21:00.222522Z",
          "iopub.status.idle": "2025-04-06T21:21:00.228264Z",
          "shell.execute_reply.started": "2025-04-06T21:21:00.222501Z",
          "shell.execute_reply": "2025-04-06T21:21:00.227359Z"
        },
        "id": "hM4hNtu87PQQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# api = KaggleApi()\n",
        "# api.authenticate()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T19:26:40.008132Z",
          "iopub.execute_input": "2025-04-06T19:26:40.008377Z",
          "iopub.status.idle": "2025-04-06T19:26:40.016003Z",
          "shell.execute_reply.started": "2025-04-06T19:26:40.008353Z",
          "shell.execute_reply": "2025-04-06T19:26:40.014579Z"
        },
        "id": "Di9dXGeu7PQQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T21:21:03.134959Z",
          "iopub.execute_input": "2025-04-06T21:21:03.135236Z",
          "iopub.status.idle": "2025-04-06T21:21:07.279724Z",
          "shell.execute_reply.started": "2025-04-06T21:21:03.135216Z",
          "shell.execute_reply": "2025-04-06T21:21:07.278689Z"
        },
        "id": "MU84fik87PQQ",
        "outputId": "9ba8df8b-3ff3-42c1-aaa1-7846002e646e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2025.1.31)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.3.0)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c shl-intern-hiring-assessment\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T21:21:07.711177Z",
          "iopub.execute_input": "2025-04-06T21:21:07.711486Z",
          "iopub.status.idle": "2025-04-06T21:21:13.91505Z",
          "shell.execute_reply.started": "2025-04-06T21:21:07.711462Z",
          "shell.execute_reply": "2025-04-06T21:21:13.913958Z"
        },
        "id": "simyHzcS7PQR",
        "outputId": "32d470d1-d8a0-47df-8687-04c0e660b3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading shl-intern-hiring-assessment.zip to /kaggle/working\n 98%|██████████████████████████████████████▏| 1.07G/1.10G [00:04<00:00, 309MB/s]\n100%|███████████████████████████████████████| 1.10G/1.10G [00:04<00:00, 253MB/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q shl-intern-hiring-assessment.zip -d /kaggle/working/\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T21:21:14.780616Z",
          "iopub.execute_input": "2025-04-06T21:21:14.780923Z",
          "iopub.status.idle": "2025-04-06T21:21:31.185082Z",
          "shell.execute_reply.started": "2025-04-06T21:21:14.780901Z",
          "shell.execute_reply": "2025-04-06T21:21:31.183886Z"
        },
        "id": "fp5jYklk7PQR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U openai-whisper"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T21:21:35.264002Z",
          "iopub.execute_input": "2025-04-06T21:21:35.264373Z",
          "iopub.status.idle": "2025-04-06T21:21:57.106655Z",
          "shell.execute_reply.started": "2025-04-06T21:21:35.264343Z",
          "shell.execute_reply": "2025-04-06T21:21:57.105573Z"
        },
        "id": "6C2uO7an7PQR",
        "outputId": "d95e718e-fc3c-44ea-9442-35f529d3163c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting openai-whisper\n  Downloading openai-whisper-20240930.tar.gz (800 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.9.0)\nCollecting triton>=2.0.0 (from openai-whisper)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->openai-whisper) (2024.2.0)\nDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=1a51cec1c28e243ebeaa266f4444c2c0f2f26fec6b4dd3cca6fbc41aa61350d4\n  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\nSuccessfully built openai-whisper\nInstalling collected packages: triton, openai-whisper\nSuccessfully installed openai-whisper-20240930 triton-3.2.0\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper language-tool-python spacy textstat librosa pandas tqdm spacy\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T21:21:57.108059Z",
          "iopub.execute_input": "2025-04-06T21:21:57.10832Z",
          "iopub.status.idle": "2025-04-06T21:22:04.07819Z",
          "shell.execute_reply.started": "2025-04-06T21:21:57.108297Z",
          "shell.execute_reply": "2025-04-06T21:22:04.077299Z"
        },
        "id": "lMozF0Bg7PQS",
        "outputId": "372678e1-ad41-4c9a-e4b5-09e821c5225b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\nCollecting language-tool-python\n  Downloading language_tool_python-2.9.2-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nCollecting textstat\n  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (2.32.3)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (5.9.5)\nRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (0.10.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.11.0a2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\nCollecting pyphen (from textstat)\n  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting cmudict (from textstat)\n  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.29.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->language-tool-python) (2025.1.31)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\nRequirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->textstat) (8.5.0)\nRequirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->textstat) (5.13.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nDownloading language_tool_python-2.9.2-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading textstat-0.7.5-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyphen, language-tool-python, cmudict, textstat\nSuccessfully installed cmudict-1.0.32 language-tool-python-2.9.2 pyphen-0.17.2 textstat-0.7.5\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T19:30:06.150099Z",
          "iopub.execute_input": "2025-04-06T19:30:06.150501Z",
          "iopub.status.idle": "2025-04-06T19:30:15.536149Z",
          "shell.execute_reply.started": "2025-04-06T19:30:06.150471Z",
          "shell.execute_reply": "2025-04-06T19:30:15.534751Z"
        },
        "id": "weH4IA4B7PQS",
        "outputId": "a821068e-0a2f-4c15-8ebd-136150585f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: en-core-web-sm\nSuccessfully installed en-core-web-sm-3.8.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "import pandas as pd\n",
        "import language_tool_python\n",
        "import spacy\n",
        "import textstat\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load models\n",
        "whisper_model = whisper.load_model(\"turbo\")\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def grammar_error_rate(text):\n",
        "    matches = tool.check(text)\n",
        "    word_count = len(text.split())\n",
        "    return len(matches) / word_count * 100 if word_count > 0 else 0\n",
        "\n",
        "def syntactic_complexity(text):\n",
        "    doc = nlp(text)\n",
        "    sentence_lengths = [len(sent.text.split()) for sent in doc.sents]\n",
        "    avg_sentence_length = sum(sentence_lengths) / len(sentence_lengths) if sentence_lengths else 0\n",
        "    complex_sentences = sum(1 for sent in doc.sents if any(tok.dep_ == \"advcl\" or tok.dep_ == \"ccomp\" for tok in sent))\n",
        "    return avg_sentence_length, complex_sentences\n",
        "\n",
        "def speaking_rate(audio_path, transcript):\n",
        "    y, sr = librosa.load(audio_path)\n",
        "    duration = librosa.get_duration(y=y, sr=sr)\n",
        "    word_count = len(transcript.split())\n",
        "    return word_count / duration if duration > 0 else 0\n",
        "\n",
        "def process_dataset(folder_path, csv_path, is_train=True):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    features = []\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
        "        audio_id = row['filename']\n",
        "        audio_file = os.path.join(folder_path, f\"{audio_id}\")\n",
        "\n",
        "        try:\n",
        "            transcript = transcribe_audio(audio_file)\n",
        "            ge_rate = grammar_error_rate(transcript)\n",
        "            avg_sent_len, complex_sent_count = syntactic_complexity(transcript)\n",
        "            rate = speaking_rate(audio_file, transcript)\n",
        "\n",
        "            data = {\n",
        "                \"id\": audio_id,\n",
        "                \"normalized_grammar_errors\": ge_rate,\n",
        "                \"avg_sentence_length\": avg_sent_len,\n",
        "                \"complex_sentence_count\": complex_sent_count,\n",
        "                \"speaking_rate\": rate\n",
        "            }\n",
        "\n",
        "            if is_train:\n",
        "                data[\"score\"] = row[\"label\"]\n",
        "\n",
        "            features.append(data)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {audio_id}: {e}\")\n",
        "\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "# Paths\n",
        "train_folder = \"audios_train\"\n",
        "test_folder = \"audios_test\"\n",
        "train_csv_path = \"train.csv\"\n",
        "test_csv_path = \"test.csv\"\n",
        "\n",
        "\n",
        "train_features = process_dataset(train_folder, train_csv_path, is_train=True)\n",
        "test_features = process_dataset(test_folder, test_csv_path, is_train=False)\n",
        "\n",
        "\n",
        "train_features.to_csv(\"train_features.csv\", index=False)\n",
        "test_features.to_csv(\"test_features.csv\", index=False)\n",
        "\n",
        "print(\"Feature extraction completed and CSV files saved.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-06T22:19:21.538731Z",
          "iopub.execute_input": "2025-04-06T22:19:21.539089Z",
          "iopub.status.idle": "2025-04-06T22:46:11.74981Z",
          "shell.execute_reply.started": "2025-04-06T22:19:21.539064Z",
          "shell.execute_reply": "2025-04-06T22:46:11.748808Z"
        },
        "id": "OZ5o3uwI7PQS",
        "outputId": "9b00eddb-f06b-4cf3-c852-81c3f5a7ee2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\nProcessing: 100%|██████████| 195/195 [26:30<00:00,  8.16s/it]   ",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Feature extraction completed and CSV files saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "model = whisper.load_model(\"turbo\")\n",
        "\n",
        "\n",
        "audio_folder = \"audios_test\"\n",
        "output_csv = \"transcriptions_test.csv\"\n",
        "\n",
        "results = []\n",
        "\n",
        "for filename in os.listdir(audio_folder):\n",
        "    if filename.endswith((\".mp3\", \".wav\", \".m4a\")):\n",
        "        audio_path = os.path.join(audio_folder, filename)\n",
        "        print(f\"Transcribing {filename}...\")\n",
        "\n",
        "        result = model.transcribe(audio_path)\n",
        "        transcription = result[\"text\"]\n",
        "\n",
        "        results.append({\n",
        "            \"filename\": filename,\n",
        "            \"transcription\": transcription\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"\\n✅ Transcriptions saved to {output_csv}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T00:06:50.507199Z",
          "iopub.execute_input": "2025-04-07T00:06:50.507573Z",
          "iopub.status.idle": "2025-04-07T00:27:09.099062Z",
          "shell.execute_reply.started": "2025-04-07T00:06:50.507531Z",
          "shell.execute_reply": "2025-04-07T00:27:09.098033Z"
        },
        "id": "6MJWbCJa7PQT",
        "outputId": "028eaa06-d8ac-4d9b-d7d8-1d28088e522f"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Transcribing audio_550.wav...\nTranscribing audio_820.wav...\nTranscribing audio_113.wav...\nTranscribing audio_735.wav...\nTranscribing audio_1280.wav...\nTranscribing audio_135.wav...\nTranscribing audio_1217.wav...\nTranscribing audio_1035.wav...\nTranscribing audio_1289.wav...\nTranscribing audio_857.wav...\nTranscribing audio_300.wav...\nTranscribing audio_137.wav...\nTranscribing audio_21.wav...\nTranscribing audio_391.wav...\nTranscribing audio_1315.wav...\nTranscribing audio_1026.wav...\nTranscribing audio_437.wav...\nTranscribing audio_109.wav...\nTranscribing audio_499.wav...\nTranscribing audio_1173.wav...\nTranscribing audio_604.wav...\nTranscribing audio_698.wav...\nTranscribing audio_287.wav...\nTranscribing audio_276.wav...\nTranscribing audio_543.wav...\nTranscribing audio_920.wav...\nTranscribing audio_1267.wav...\nTranscribing audio_512.wav...\nTranscribing audio_348.wav...\nTranscribing audio_656.wav...\nTranscribing audio_386.wav...\nTranscribing audio_1293.wav...\nTranscribing audio_1240.wav...\nTranscribing audio_709.wav...\nTranscribing audio_1123.wav...\nTranscribing audio_107.wav...\nTranscribing audio_1159.wav...\nTranscribing audio_448.wav...\nTranscribing audio_500.wav...\nTranscribing audio_322.wav...\nTranscribing audio_692.wav...\nTranscribing audio_159.wav...\nTranscribing audio_68.wav...\nTranscribing audio_805.wav...\nTranscribing audio_428.wav...\nTranscribing audio_888.wav...\nTranscribing audio_488.wav...\nTranscribing audio_148.wav...\nTranscribing audio_95.wav...\nTranscribing audio_274.wav...\nTranscribing audio_811.wav...\nTranscribing audio_1278.wav...\nTranscribing audio_320.wav...\nTranscribing audio_177.wav...\nTranscribing audio_151.wav...\nTranscribing audio_1054.wav...\nTranscribing audio_1089.wav...\nTranscribing audio_713.wav...\nTranscribing audio_286.wav...\nTranscribing audio_519.wav...\nTranscribing audio_89.wav...\nTranscribing audio_360.wav...\nTranscribing audio_1058.wav...\nTranscribing audio_767.wav...\nTranscribing audio_1195.wav...\nTranscribing audio_308.wav...\nTranscribing audio_546.wav...\nTranscribing audio_1205.wav...\nTranscribing audio_1178.wav...\nTranscribing audio_719.wav...\nTranscribing audio_882.wav...\nTranscribing audio_1124.wav...\nTranscribing audio_1122.wav...\nTranscribing audio_1193.wav...\nTranscribing audio_971.wav...\nTranscribing audio_435.wav...\nTranscribing audio_633.wav...\nTranscribing audio_746.wav...\nTranscribing audio_1116.wav...\nTranscribing audio_885.wav...\nTranscribing audio_1169.wav...\nTranscribing audio_138.wav...\nTranscribing audio_525.wav...\nTranscribing audio_884.wav...\nTranscribing audio_800.wav...\nTranscribing audio_1292.wav...\nTranscribing audio_1291.wav...\nTranscribing audio_1091.wav...\nTranscribing audio_554.wav...\nTranscribing audio_1214.wav...\nTranscribing audio_662.wav...\nTranscribing audio_330.wav...\nTranscribing audio_1138.wav...\nTranscribing audio_529.wav...\nTranscribing audio_932.wav...\nTranscribing audio_1321.wav...\nTranscribing audio_683.wav...\nTranscribing audio_1166.wav...\nTranscribing audio_408.wav...\nTranscribing audio_29.wav...\nTranscribing audio_10.wav...\nTranscribing audio_580.wav...\nTranscribing audio_281.wav...\nTranscribing audio_165.wav...\nTranscribing audio_66.wav...\nTranscribing audio_644.wav...\nTranscribing audio_998.wav...\nTranscribing audio_521.wav...\nTranscribing audio_1183.wav...\nTranscribing audio_858.wav...\nTranscribing audio_556.wav...\nTranscribing audio_733.wav...\nTranscribing audio_1215.wav...\nTranscribing audio_1243.wav...\nTranscribing audio_1179.wav...\nTranscribing audio_1242.wav...\nTranscribing audio_285.wav...\nTranscribing audio_72.wav...\nTranscribing audio_394.wav...\nTranscribing audio_958.wav...\nTranscribing audio_599.wav...\nTranscribing audio_48.wav...\nTranscribing audio_897.wav...\nTranscribing audio_388.wav...\nTranscribing audio_433.wav...\nTranscribing audio_487.wav...\nTranscribing audio_572.wav...\nTranscribing audio_922.wav...\nTranscribing audio_1323.wav...\nTranscribing audio_263.wav...\nTranscribing audio_34.wav...\nTranscribing audio_1013.wav...\nTranscribing audio_676.wav...\nTranscribing audio_180.wav...\nTranscribing audio_1061.wav...\nTranscribing audio_1068.wav...\nTranscribing audio_702.wav...\nTranscribing audio_196.wav...\nTranscribing audio_569.wav...\nTranscribing audio_153.wav...\nTranscribing audio_908.wav...\nTranscribing audio_545.wav...\nTranscribing audio_261.wav...\nTranscribing audio_306.wav...\nTranscribing audio_235.wav...\nTranscribing audio_665.wav...\nTranscribing audio_172.wav...\nTranscribing audio_75.wav...\nTranscribing audio_541.wav...\nTranscribing audio_401.wav...\nTranscribing audio_217.wav...\nTranscribing audio_179.wav...\nTranscribing audio_1190.wav...\nTranscribing audio_1033.wav...\nTranscribing audio_1022.wav...\nTranscribing audio_1297.wav...\nTranscribing audio_540.wav...\nTranscribing audio_1115.wav...\nTranscribing audio_379.wav...\nTranscribing audio_20.wav...\nTranscribing audio_1176.wav...\nTranscribing audio_831.wav...\nTranscribing audio_1101.wav...\nTranscribing audio_1317.wav...\nTranscribing audio_422.wav...\nTranscribing audio_641.wav...\nTranscribing audio_221.wav...\nTranscribing audio_4.wav...\nTranscribing audio_759.wav...\nTranscribing audio_1012.wav...\nTranscribing audio_158.wav...\nTranscribing audio_949.wav...\nTranscribing audio_690.wav...\nTranscribing audio_726.wav...\nTranscribing audio_1081.wav...\nTranscribing audio_103.wav...\nTranscribing audio_1286.wav...\nTranscribing audio_1311.wav...\nTranscribing audio_770.wav...\nTranscribing audio_706.wav...\nTranscribing audio_1256.wav...\nTranscribing audio_564.wav...\nTranscribing audio_290.wav...\nTranscribing audio_1048.wav...\nTranscribing audio_225.wav...\nTranscribing audio_282.wav...\nTranscribing audio_1275.wav...\nTranscribing audio_959.wav...\nTranscribing audio_1019.wav...\nTranscribing audio_762.wav...\nTranscribing audio_321.wav...\nTranscribing audio_198.wav...\nTranscribing audio_841.wav...\nTranscribing audio_218.wav...\nTranscribing audio_19.wav...\n\n✅ Transcriptions saved to transcriptions_test.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score\n",
        "import string\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "transcriptions_df = pd.read_csv(\"transcriptions.csv\")\n",
        "scores_df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "df = pd.merge(transcriptions_df, scores_df, on=\"filename\")\n",
        "\n",
        "# Preprocessing Function\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [w for w in tokens if w not in stop_words and len(w) > 1]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"clean_text\"] = df[\"transcription\"].apply(preprocess)\n",
        "\n",
        "\n",
        "# Feature Extraction (TF-IDF)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform(df[\"clean_text\"]).toarray()\n",
        "y = df[\"label\"].values\n",
        "\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Train XGBoost Regressor\n",
        "model = make_pipeline(StandardScaler(), XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42))\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict & Map to Valid Scores\n",
        "valid_scores = np.array([0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0])\n",
        "\n",
        "def map_to_closest_valid(y_preds, valid_scores):\n",
        "    return np.array([valid_scores[np.abs(valid_scores - y).argmin()] for y in y_preds])\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_mapped = map_to_closest_valid(y_pred, valid_scores)\n",
        "y_test_mapped = map_to_closest_valid(y_test, valid_scores)\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "# accuracy = accuracy_score(y_test_mapped, y_pred_mapped)\n",
        "\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "print(f\"Mean Absolute Error: {mae:.3f}\")\n",
        "print(f\"Mean Squared Error: {mse:.3f}\")\n",
        "print(f\"Mapped Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "joblib.dump(model, \"xgboost_model.joblib\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.joblib\")\n",
        "print(\"✅ Model and vectorizer saved.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T01:04:54.012107Z",
          "iopub.execute_input": "2025-04-07T01:04:54.012458Z",
          "iopub.status.idle": "2025-04-07T01:04:54.679173Z",
          "shell.execute_reply.started": "2025-04-07T01:04:54.01243Z",
          "shell.execute_reply": "2025-04-07T01:04:54.678404Z"
        },
        "id": "gL33ZYqT7PQT",
        "outputId": "d5d617dc-2040-45a3-e71d-8aeacfefe745"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nR² Score: 0.832\nMean Absolute Error: 0.360\nMean Squared Error: 0.208\nMapped Accuracy: 86.52%\n✅ Model and vectorizer saved.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_df = pd.read_csv(\"transcriptions_test.csv\")\n",
        "\n",
        "\n",
        "test_df[\"clean_text\"] = test_df[\"transcription\"].apply(preprocess)\n",
        "\n",
        "\n",
        "X_test_new = vectorizer.transform(test_df[\"clean_text\"]).toarray()\n",
        "\n",
        "\n",
        "y_pred_new = model.predict(X_test_new)\n",
        "\n",
        "\n",
        "y_pred_mapped_new = map_to_closest_valid(y_pred_new, valid_scores)\n",
        "\n",
        "\n",
        "test_df[\"label\"] = y_pred_mapped_new\n",
        "\n",
        "\n",
        "test_df[[\"filename\", \"label\"]].to_csv(\"predicted_scores.csv\", index=False)\n",
        "\n",
        "print(\"✅ Predictions saved to 'predicted_scores.csv'\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-07T01:07:44.347973Z",
          "iopub.execute_input": "2025-04-07T01:07:44.348334Z",
          "iopub.status.idle": "2025-04-07T01:07:44.494755Z",
          "shell.execute_reply.started": "2025-04-07T01:07:44.348305Z",
          "shell.execute_reply": "2025-04-07T01:07:44.49383Z"
        },
        "id": "id3WJIj67PQU",
        "outputId": "f59aa588-478e-4ac3-cff0-3addffe89aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ Predictions saved to 'predicted_scores.csv'\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}